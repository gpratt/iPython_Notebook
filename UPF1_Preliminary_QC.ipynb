{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pybedtools\n",
      "import pysam\n",
      "from collections import defaultdict, Counter\n",
      "import pandas as pd\n",
      "\n",
      "from IPython.core.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def parse_star_file(star_file):\n",
      "    star_dict = {}\n",
      "\n",
      "    star_dict[\"Started job on\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Started mapping on\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Finished on\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Mapping speed, Million of reads per hour\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_file.next()\n",
      "    star_dict[\"Number of input reads\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Average input read length\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_file.next()\n",
      "    star_dict[\"Uniquely mapped reads number\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Uniquely mapped reads %\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Average mapped length\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of splices: Total\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of splices: Annotated (sjdb)\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of splices: GT/AG\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of splices: GC/AG\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of splices: AT/AC\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of splices: Non-canonical\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Mismatch rate per base, percent\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Deletion rate per base\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Deletion average length\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Insertion rate per base\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Insertion average length\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_file.next()\n",
      "    star_dict[\"Number of reads mapped to multiple loci\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"% of reads mapped to multiple loci\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"Number of reads mapped to too many loci\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"% of reads mapped to too many loci\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_file.next()\n",
      "    star_dict[\"% of reads unmapped: too many mismatches\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"% of reads unmapped: too short\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    star_dict[\"% of reads unmapped: other\"] = star_file.next().strip().split(\"|\")[1].strip()\n",
      "    return star_dict\n",
      "\n",
      "def parse_peak_metrics(fn):\n",
      "    with open(fn) as file_handle:\n",
      "        file_handle.next()\n",
      "        return {'spot' : float(file_handle.next())}\n",
      "    \n",
      "def parse_nrf_file(nrf_file):\n",
      "    with open(nrf_file) as nrf_file:\n",
      "        names = nrf_file.next().strip().split()\n",
      "        values = nrf_file.next().strip().split()\n",
      "        return {name : float(value) for name, value in zip(names, values)} \n",
      "    \n",
      "def parse_rm_duped_metrics_file(nrf_file):\n",
      "    total_count = 0\n",
      "    removed_count = 0 \n",
      "    \n",
      "    with open(nrf_file) as nrf_file:\n",
      "        df = pd.read_csv(nrf_file, sep=\"\\t\")\n",
      "        sum(df.total_count) - sum(df.removed_count)\n",
      "        \n",
      "        return {\"total_count\" : sum(df.total_count), \n",
      "                \"removed_count\" : sum(df.removed_count), \n",
      "                \"Usable Reads\" : sum(df.total_count) - sum(df.removed_count)}\n",
      "\n",
      "def commas(x):\n",
      "    try:\n",
      "        return \"{:,}\".format(int(x))\n",
      "    except:\n",
      "        return \"nan\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /nas3/gpratt/projects/upf1/analysis/analysis_v2/clip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/nas/nas0/gpratt/projects/upf1/analysis/analysis_v2/clip\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "spot_files = !ls *peaks.metrics\n",
      "spot_df = pd.DataFrame({\".\".join(spot_file.split(\".\")[0:2]): parse_peak_metrics(spot_file) for spot_file in spot_files}).transpose()\n",
      "\n",
      "nrf_files = !ls *.NRF\n",
      "nrf_frame = pd.DataFrame({\".\".join(nrf_file.split(\".\")[0:2]) : parse_nrf_file(nrf_file) for nrf_file in nrf_files}).transpose()\n",
      "\n",
      "qc_files = !ls *.final.out\n",
      "star_frame = pd.DataFrame({\".\".join(qc_file.split(\".\")[0:2]) : parse_star_file(open(qc_file)) for qc_file in qc_files}).transpose()\n",
      "\n",
      "rm_duped_metrics = !ls *.rmDup.metrics\n",
      "rm_duped_metrics = pd.DataFrame({\".\".join(rm_duped_metric.split(\".\")[0:2]) : parse_rm_duped_metrics_file(rm_duped_metric) for rm_duped_metric in rm_duped_metrics}).transpose()\n",
      "\n",
      "peaks_files = !ls *.peaks.bed\n",
      "peaks_metrics = pd.DataFrame({\".\".join(peaks_file.split(\".\")[0:2]) : {\"Num Peaks\" : len(pybedtools.BedTool(peaks_file))} for peaks_file in peaks_files}).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combined_df = pd.merge(nrf_frame, star_frame, left_index=True, right_index=True, how=\"outer\")\n",
      "combined_df = pd.merge(combined_df, spot_df, left_index=True, right_index=True, how=\"outer\")\n",
      "combined_df = pd.merge(combined_df, rm_duped_metrics, left_index=True, right_index=True, how=\"outer\")\n",
      "combined_df = pd.merge(combined_df, peaks_metrics, left_index=True, right_index=True, how=\"outer\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(filtered_df[\"Number of input reads\"].ix['UPF1_3_4.polyATrim'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "float"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_df = combined_df[[\"Number of input reads\", \n",
      "                            \"Uniquely mapped reads number\",\n",
      "                            \"Uniquely mapped reads %\",\n",
      "                            \"Usable Reads\",\n",
      "                            \"spot\",\n",
      "                            \"Num Peaks\"]]\n",
      "\n",
      "\n",
      "HTML(filtered_df.to_html(formatters={\"Number of input reads\" : commas,\n",
      "                             \"Uniquely mapped reads number\" : commas,\n",
      "                             \"Usable Reads\" : commas,\n",
      "                             \"Num Peaks\": commas} ))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Number of input reads</th>\n",
        "      <th>Uniquely mapped reads number</th>\n",
        "      <th>Uniquely mapped reads %</th>\n",
        "      <th>Usable Reads</th>\n",
        "      <th>spot</th>\n",
        "      <th>Num Peaks</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>289_FlagControl_NoIndex_L005_R1.polyATrim</th>\n",
        "      <td>  18,321,806</td>\n",
        "      <td>  13,763,335</td>\n",
        "      <td> 75.12%</td>\n",
        "      <td>   45,755</td>\n",
        "      <td>      NaN</td>\n",
        "      <td> 1,209</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>290_FlagDEAA_NoIndex_L006_R1.polyATrim</th>\n",
        "      <td>  30,306,021</td>\n",
        "      <td>  26,307,914</td>\n",
        "      <td> 86.81%</td>\n",
        "      <td>  300,996</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>10,958</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>291_FlagK498A_NoIndex_L007_R1.polyATrim</th>\n",
        "      <td>  30,230,531</td>\n",
        "      <td>  26,009,127</td>\n",
        "      <td> 86.04%</td>\n",
        "      <td>  287,629</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>10,619</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>FJM_W1_NoIndex_L001_R1.polyATrim</th>\n",
        "      <td>  54,607,038</td>\n",
        "      <td>  43,449,517</td>\n",
        "      <td> 79.57%</td>\n",
        "      <td>4,115,322</td>\n",
        "      <td> 0.101230</td>\n",
        "      <td>13,024</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>FM_UPF_1_NoIndex_L004_R1.polyATrim</th>\n",
        "      <td> 107,025,437</td>\n",
        "      <td>  86,435,907</td>\n",
        "      <td> 80.76%</td>\n",
        "      <td>1,961,264</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>21,206</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>FM_UPF_2_NoIndex_L005_R1.polyATrim</th>\n",
        "      <td> 125,846,972</td>\n",
        "      <td> 103,064,724</td>\n",
        "      <td> 81.90%</td>\n",
        "      <td>2,395,744</td>\n",
        "      <td> 0.269398</td>\n",
        "      <td>23,244</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>FM_UPF_3_NoIndex_L006_R1.polyATrim</th>\n",
        "      <td> 101,336,605</td>\n",
        "      <td>  81,361,995</td>\n",
        "      <td> 80.29%</td>\n",
        "      <td>1,927,544</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>21,699</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>FM_UPF_4_NoIndex_L007_R1.polyATrim</th>\n",
        "      <td> 134,341,127</td>\n",
        "      <td> 110,863,287</td>\n",
        "      <td> 82.52%</td>\n",
        "      <td>2,054,154</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>28,593</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>UPF1_1_2.polyATrim</th>\n",
        "      <td>         NaN</td>\n",
        "      <td>         NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>      nan</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>18,204</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>UPF1_3_4.polyATrim</th>\n",
        "      <td>         NaN</td>\n",
        "      <td>         NaN</td>\n",
        "      <td>    NaN</td>\n",
        "      <td>      nan</td>\n",
        "      <td>      NaN</td>\n",
        "      <td>15,722</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>WT_NoIndex_L006_R1.polyATrim</th>\n",
        "      <td> 111,361,328</td>\n",
        "      <td>  92,852,818</td>\n",
        "      <td> 83.38%</td>\n",
        "      <td>  475,282</td>\n",
        "      <td> 0.553020</td>\n",
        "      <td>13,403</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "<IPython.core.display.HTML at 0x2aaaac0c9390>"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "filtered_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}