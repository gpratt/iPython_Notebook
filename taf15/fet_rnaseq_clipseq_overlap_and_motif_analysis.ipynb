{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas3/gpratt/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1318: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict, Counter, defaultdict\n",
    "import glob \n",
    "import itertools\n",
    "from itertools import izip\n",
    "import os\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "import gffutils\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import clipper\n",
    "from clipper.src import CLIP_analysis\n",
    "from clipper.src import CLIP_analysis_display\n",
    "from gscripts.general import dataviz\n",
    "from gscripts import GO\n",
    "from gscripts.general import region_helpers\n",
    "\n",
    "fig_dir = \".\"\n",
    "img_dir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Set Up Data that I'll need Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "regions = OrderedDict()\n",
    "regions['all'] = 'All'\n",
    "regions[\"cds\"] = \"CDS\"\n",
    "regions[\"three_prime_utrs\"] = \"3' UTR\"\n",
    "regions[\"five_prime_utrs\"] = \"5' UTR\"\n",
    "regions[\"proxintron500\"] = \"Proximal\\nIntron\"\n",
    "regions[\"distintron500\"] = \"Distal\\nIntron\"\n",
    "\n",
    "assigned_regions = regions.copy()\n",
    "del assigned_regions['all'] \n",
    "def move_name(interval):\n",
    "    interval.name = interval[12]\n",
    "    return interval\n",
    "\n",
    "viz = CLIP_analysis_display.ClipVisualization()\n",
    "\n",
    "def plot_denovo_motifs(bedtool, fig=None):\n",
    "    root = \"/nas3/gpratt/iPython_Notebook/taf15/\"\n",
    "    out_dir = os.path.join(root, \"assigned/\")\n",
    "    fasta_dir = os.path.join(root, \"fasta/\")\n",
    "    cluster_name = os.path.basename(bedtool.fn)\n",
    "    cluster_out = os.path.join(root, bedtool.fn + \"_homer\")\n",
    "                               \n",
    "    cluster_regions = CLIP_analysis.assign_to_regions(tool=bedtool, \n",
    "                                                      clusters=cluster_name, \n",
    "                                                      regions=assigned_regions, \n",
    "                                                      assigned_dir = out_dir,\n",
    "                                                      species=\"mm9\"\n",
    "                                                      )\n",
    "\n",
    "    CLIP_analysis.make_fasta_files_from_regions(cluster_regions, cluster_name, fasta_dir, \"/nas3/yeolab/Genome/ucsc/mm9/chromosomes/all.fa\")\n",
    "    CLIP_analysis.calculate_homer_motifs([5,6,7,8], regions, cluster_name, fasta_dir, cluster_out)\n",
    "\n",
    "    if fig is None:\n",
    "        fig = plt.figure(figsize=(20, 20))\n",
    "        \n",
    "    full_grid = gridspec.GridSpec(6, 4)\n",
    "    motif_grid = gridspec.GridSpecFromSubplotSpec(1, 6,\n",
    "                                                  subplot_spec=full_grid[4:6, :],\n",
    "                                                  hspace=0,\n",
    "                                                  wspace=0)\n",
    "\n",
    "    viz.build_common_motifs(motif_grid, cluster_out)\n",
    "    \n",
    "def plot_distributions(bedtool, ax=None, label=None):\n",
    "    if not ax:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1,1,1)\n",
    "        \n",
    "    lens = [len(interval) for interval in bedtool]\n",
    "    counts = Counter(lens)\n",
    "    ax.plot(counts.keys(), counts.values(), label=label)\n",
    "\n",
    "    \n",
    "def gencode_to_ensembl(gene_list):\n",
    "    for gene in gene_list:\n",
    "        yield gene.split(\".\")[0]\n",
    "        \n",
    "def plot_go_enrichment(df, filter_value=None, max_terms=None, **kwargs):\n",
    "    df = df.copy()\n",
    "    new_index = []\n",
    "    for index, description in izip(df.index, df['GO Term Description']):\n",
    "        new_index.append(list(index[:-1]) + [description])\n",
    "    df.index = pd.MultiIndex.from_tuples(new_index)\n",
    "\n",
    "    go_matrix = df['Bonferroni-corrected Hypergeometric p-Value'].apply(lambda x: -1 * np.log10(x))\n",
    "    go_matrix = go_matrix.unstack(range(len(go_matrix.index.levels) - 1))\n",
    "    go_matrix = go_matrix.fillna(0)\n",
    "    \n",
    "    #Set cutoff on values \n",
    "    if filter_value is not None:\n",
    "        go_matrix = go_matrix[go_matrix.apply(max, axis=1) > filter_value]\n",
    "    \n",
    "    #Set cutoff on number of go terms to show\n",
    "    if max_terms is not None:\n",
    "        go_matrix = go_matrix.ix[go_matrix.max(axis=1).order(ascending=False).index].ix[:max_terms]\n",
    "    sns.clustermap(go_matrix, robust=True, **kwargs)\n",
    "\n",
    "    \n",
    "gene_id_to_name = region_helpers.gene_id_to_name(\"/nas3/gpratt/gencode/gencode.vM1.annotation.gtf.db\")\n",
    "gene_id_to_type = region_helpers.gene_id_to_type(\"/nas3/gpratt/gencode/gencode.vM1.annotation.gtf.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Old Kasey Method of getting merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nas/nas0/gpratt/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/nas/nas0/gpratt/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "rpkms = glob.glob(\"/nas3/gpratt/projects/fet_family/analysis/fet_family_v1/*.rpkm\")\n",
    "rpkms = {os.path.basename(rpkm).split(\".\")[0]: pd.read_table(rpkm, index_col=0).RPKM for rpkm in rpkms}\n",
    "rpkms = pd.concat(rpkms).unstack().T\n",
    "\n",
    "master_df = pd.read_excel(\"/nas3/gpratt/Dropbox/TAF15/Data/striatum_overlap/FETT_clip_plus_halflife.xlsx\", \"fold_changes\", index_col=0)\n",
    "\n",
    "master_df = master_df.drop(\"Unnamed: 1\", axis=1)\n",
    "\n",
    "master_df['FUS UTR3 clip'][master_df['FUS UTR3 clip'] == \"none\"] = 0\n",
    "#master_df['TAF UTR3 clip'][master_df['TAF UTR3 clip'] == \"none\"] = 0\n",
    "master_df['TDP43 UTR3 clip'][master_df['TDP43 UTR3 clip'] == \"none\"] = 0\n",
    "master_df = master_df.astype(float)\n",
    "master_df['TAF log2 Fold change'] = master_df['TAF Fold change'].apply(np.log2)\n",
    "\n",
    "master_df['FUS_3UTR_bound'] = master_df['FUS UTR3 clip'] > 0\n",
    "master_df['TAF_3UTR_bound'] = master_df['TAF UTR3 clip'] > 0\n",
    "master_df['TDP43_3UTR_bound'] = master_df['TDP43 UTR3 clip'] > 0\n",
    "\n",
    "master_df['TDP43_FUS_3UTR_bound'] = master_df['TDP43_3UTR_bound'] & master_df['FUS_3UTR_bound']\n",
    "master_df['TAF_FUS_3UTR_bound'] = master_df['TAF_3UTR_bound'] & master_df['FUS_3UTR_bound']\n",
    "master_df['TDP43_TAF_3UTR_bound'] = master_df['TDP43_3UTR_bound'] & master_df['TAF_3UTR_bound']\n",
    "master_df['TDP43_TAF_FUS_3UTR_bound'] = master_df['TDP43_3UTR_bound'] & master_df['TAF_3UTR_bound'] & master_df['FUS_3UTR_bound']\n",
    "\n",
    "joined_df = rpkms.join(master_df)\n",
    "joined_df.to_csv(\"/nas3/gpratt/Dropbox/TAF15/Data/rpkms_and_binding.csv\")\n",
    "\n",
    "rpkms.to_csv(\"/nas3/gpratt/Dropbox/TAF15/Data/rpkms_and_binding.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DESeq Differental Expression Analysis / Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes = pybedtools.BedTool(\"/nas3/gpratt/clipper/clipper/data/regions/mm9_genes.bed\")\n",
    "\n",
    "rbps = {\"taf15\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/data/stuff_for_KK/TAF15_combined_notrim_ingenes_clusters_mm950.bed\"),\n",
    " \"fus\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/data/stuff_for_KK/TLS_hiseq_notrim_ingenes_clusters_mm950.bed\"),\n",
    " \"tdp43\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/data/stuff_for_KK/TDP43brainclip_MP41_kcomb_notrim_ingenes_clusters_mm950.bed\"),\n",
    " }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of names must match number of levels in MultiIndex.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-fd3b47a784c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcombined_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrbp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrbp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/nas3/gpratt/Dropbox/TAF15/Data/mouse_integration/deseq/*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"gene_name\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgene_id_to_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgene_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgene_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcombined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tuples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrbp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgene\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mrbp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgene\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"rbp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cell_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"geneid\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/nas3/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mfrom_tuples\u001b[1;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[0;32m   4675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4676\u001b[0m         return MultiIndex.from_arrays(arrays, sortorder=sortorder,\n\u001b[1;32m-> 4677\u001b[1;33m                                       names=names)\n\u001b[0m\u001b[0;32m   4678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4679\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/nas3/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36mfrom_arrays\u001b[1;34m(cls, arrays, sortorder, names)\u001b[0m\n\u001b[0;32m   4629\u001b[0m         return MultiIndex(levels=levels, labels=labels,\n\u001b[0;32m   4630\u001b[0m                           \u001b[0msortorder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msortorder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4631\u001b[1;33m                           verify_integrity=False)\n\u001b[0m\u001b[0;32m   4632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4633\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/nas3/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, levels, labels, sortorder, names, copy, verify_integrity, _set_identity, name, **kwargs)\u001b[0m\n\u001b[0;32m   3915\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m             \u001b[1;31m# handles name validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3917\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3919\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msortorder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/nas3/gpratt/anaconda/lib/python2.7/site-packages/pandas/core/index.pyc\u001b[0m in \u001b[0;36m_set_names\u001b[1;34m(self, names, level, validate)\u001b[0m\n\u001b[0;32m   4260\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4261\u001b[0m             raise ValueError(\n\u001b[1;32m-> 4262\u001b[1;33m                 'Length of names must match number of levels in MultiIndex.')\n\u001b[0m\u001b[0;32m   4263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of names must match number of levels in MultiIndex."
     ]
    }
   ],
   "source": [
    "combined_df = pd.concat({os.path.basename(rbp).split(\".\")[0]: pd.read_csv(rbp, index_col=0) for rbp in glob.glob(\"/nas3/gpratt/Dropbox/TAF15/Data/mouse_integration/deseq/*\")})\n",
    "combined_df[\"gene_name\"] = [gene_id_to_name[gene_id] for gene_id in combined_df.index.get_level_values(level=1)]\n",
    "combined_df.index = pd.MultiIndex.from_tuples([rbp.split(\"_\") + [gene] for rbp, gene in combined_df.index], names=[\"rbp\", \"cell_type\", \"geneid\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MA Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(27 + 12.) / (27 + 2 + 7 + 12 + 6 + 1 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_rows = 4\n",
    "num_cols = 4\n",
    "with dataviz.Figure(os.path.join(img_dir, \"ma_plots.svg\"), figsize=(num_cols * 2.5,num_rows * 2.5)) as fig:\n",
    "    for x, (name, df) in enumerate(combined_df.groupby(level=[\"rbp\", \"cell_type\"])):\n",
    "        ax = fig.add_subplot(num_rows, num_cols, x +1)\n",
    "        dataviz.ma_plot(df, ax)\n",
    "        ax.set_title(\" \".join(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merge in Binding to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes = pybedtools.BedTool(\"/nas3/gpratt/clipper/clipper/data/regions/mm9_genes.bed\")\n",
    "\n",
    "rbps = {\"taf15\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/analysis/mouse_clip_v5/TAF15_WholeBrain.merged.peaks.kasey.bed\"),\n",
    "        'tdp43': pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/analysis/mouse_clip_v5/TDP43_WholeBrain.merged.peaks.kasey.bed\"),\n",
    "        'tls': pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/analysis/mouse_clip_v5/TLS_WholeBrain.merged.peaks.kasey.bed\"),}\n",
    "\n",
    "\n",
    "# rbps = {\"taf15\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/data/stuff_for_KK/TAF15_combined_notrim_ingenes_clusters_mm950.bed\"),\n",
    "#         \"tls\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/data/stuff_for_KK/TLS_hiseq_notrim_ingenes_clusters_mm950.bed\"),\n",
    "#         \"tdp43\": pybedtools.BedTool(\"/nas3/gpratt/projects/fet_family/data/stuff_for_KK/TDP43brainclip_MP41_kcomb_notrim_ingenes_clusters_mm950.bed\"),\n",
    "#  }\n",
    "\n",
    "binding_df = []\n",
    "for name, rbp in rbps.items():\n",
    "    overlapping_genes = rbp.intersect(genes, wo=True, s=True).each(move_name).saveas()\n",
    "\n",
    "    cluster_regions = CLIP_analysis.assign_to_regions(overlapping_genes, \"overlapping\", \n",
    "                                    assigned_regions, \"assigned\", nrand=0, species=\"mm9\")\n",
    "    \n",
    "    for region in cluster_regions.keys():\n",
    "        gene_names = pd.Series(Counter([interval.name.split(\",\")[0] for interval in cluster_regions[region]['real']]),\n",
    "                                name=name + \"_\" + region)\n",
    "        gene_names.name = (name, region)\n",
    "        binding_df.append(gene_names)\n",
    "binding_df = pd.concat(binding_df,axis=1)\n",
    "binding_df.columns = pd.MultiIndex.from_tuples(binding_df.columns)\n",
    "binding_df = binding_df.T\n",
    "binding_df = binding_df.stack()\n",
    "binding_df.index.names = ['rbp', 'region', 'gene_id']\n",
    "binding_df = binding_df.sort_index()\n",
    "binding_df = pd.DataFrame(binding_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sig_df = combined_df[combined_df.padj <= .01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#THIS IS BROKEN, BUT I DON'T CARE RIGHT NOW\n",
    "output = combined_df.swaplevel(0,1).unstack().copy()\n",
    "output.columns = [\"_\".join(col) for col in output.columns]\n",
    "output = combined_df.join(binding_df).fillna(0)\n",
    "#output.to_csv(\"/nas3/gpratt/Dropbox/TAF15/Data/fold_change_and_binding.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#HTML(output[output['tdp43_distintron500'] > 0].head().to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result = defaultdict(dict)\n",
    "#for name, df in sig_df.groupby(level=0):\n",
    "#    bound_df = df.ix[name].join(binding_df).fillna(0)\n",
    "#    for column in binding_df.columns:\n",
    "#        result[name][column] = bound_df[bound_df[column] > 0]['log2FoldChange'].values\n",
    "#        if len(result[name][column]) == 0:\n",
    "#            result[name][column] = [0]\n",
    "#result = pd.DataFrame(result)\n",
    "#result.to_csv(\"/nas3/gpratt/Dropbox/TAF15/Data/significant_values.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with dataviz.Figure(os.path.join(fig_dir, \"foo.svg\"), figsize=(6,24)) as fig:\n",
    "#    for x, rbp in enumerate(result.drop(\"tia1\", axis=1).columns):\n",
    "#        rbp_name = rbp.split(\"_\")[0]\n",
    "#        if rbp_name == \"tls\":\n",
    "#            rbp_name = \"fus\"\n",
    "#        ax = fig.add_subplot(4,1,x + 1)\n",
    "#        ax.boxplot(result[rbp][[index for index in result[rbp].index if rbp_name in index]])\n",
    "#        ax.set_xticklabels([index for index in result[rbp].index if rbp_name in index], rotation=90)\n",
    "#        ax.set_ylim(-5, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#For Anthony, getting Human Genes that are bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://uswest.ensembl.org%2C%20ip-10-249-130-98.us-west-1.compute.internal:8000/biomart/martview/5f7dcf4b81c7c351d1d1af7d51d0f5ba?VIRTUALSCHEMANAME=default&ATTRIBUTES=mmusculus_gene_ensembl.default.homologs.ensembl_gene_id|mmusculus_gene_ensembl.default.homologs.ensembl_transcript_id|mmusculus_gene_ensembl.default.homologs.hsapiens_homolog_ensembl_gene&FILTERS=mmusculus_gene_ensembl.default.filters.with_homolog_hsap.only&VISIBLEPANEL=attributepanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gene_id_to_name = region_helpers.gene_id_to_name(\"/nas3/gpratt/gencode/gencode.v17.annotation.gtf.db\")\n",
    "gene_id_to_name = {key.split(\".\")[0]:value for key, value in gene_id_to_name.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filtered_binding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mouse_human_genes = pd.read_table(\"/nas3/gpratt/projects/taf15/mouse_human_genes.txt\", index_col=0)\n",
    "mouse_human_genes = dict(mouse_human_genes['Human Ensembl Gene ID'].iterkv())\n",
    "\n",
    "filtered_binding = binding_df.ix[[index.split(\".\")[0] in mouse_human_genes for index in binding_df.index.get_level_values(\"gene_id\")]]\n",
    "filtered_binding['human_gene_id'] = [mouse_human_genes[index.split(\".\")[0]] for index in filtered_binding.index.get_level_values(\"gene_id\")]\n",
    "\n",
    "#filtered_binding_hg19 = filtered_binding.ix[[index.split(\".\")[0] in gene_id_to_name.values for index in filtered_binding.index]]\n",
    "#filtered_binding_hg19.index = [gene_id_to_name[index] for index in filtered_binding.index if index in index in gene_id_to_name]\n",
    "\n",
    "filtered_binding.to_csv(\"/nas3/gpratt/Dropbox/TAF15/Data/mRNA_stab/binding_mapping.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Motif Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_denovo_motifs(rbps['tdp43'])\n",
    "plot_denovo_motifs(rbps['fus'])\n",
    "plot_denovo_motifs(rbps['taf15'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#GO Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Done in Supp figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get spatial clustering of motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!findMotif -motif=GGTAAGT -bedOutput /nas3/yeolab/Genome/ucsc/mm9/chromosomes/all.fa  > ggtaagt.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assigned_regions, regions = CLIP_analysis.regions_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def intersection(a, b=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    A : bedtool\n",
    "    B : bedtool\n",
    "    Returns A - B and A intersect B \n",
    "    A with b and returns everything in a but not b and everything in a but... ???\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    overlapping = a.intersect(b, wa=True, u=True, stream=True).saveas()\n",
    "    remaining = a.intersect(b, wa=True, v=True, stream=True).saveas()\n",
    "\n",
    "    return remaining, overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_shuffled_strand(shuffled_tool, regions_file):\n",
    "    \"\"\"\n",
    "    Fixes strand of shuffled tool if there was an include file used\n",
    "\n",
    "    Chooses the first overlapping thing as the correct strand, if there is anti-sense transcription\n",
    "    this will fail\n",
    "    shuffled_tool: a sorted shuffled bedtool\n",
    "    shuffled_file: incl file that did the shuffling\n",
    "    \"\"\"\n",
    "\n",
    "    regions_tool = pybedtools.BedTool(regions_file)\n",
    "    intersected = shuffled_tool.intersect(regions_file, wao=True, stream=True, sorted=True).saveas()\n",
    "\n",
    "    #Don't think about refactoring this because of leaky files in pybedtools\n",
    "    shuffled_tool_field_count = shuffled_tool.field_count()\n",
    "    regions_tool_field_count = regions_tool.field_count()\n",
    "\n",
    "    total_header_size = shuffled_tool_field_count + regions_tool_field_count + 1\n",
    "\n",
    "    intersected = intersected.to_dataframe(names=range(total_header_size))\n",
    "    intersected = intersected.groupby([0,1,2,3]).first()\n",
    "    if regions_tool.file_type == \"bed\":\n",
    "        intersected[5] = intersected[shuffled_tool_field_count + 5]\n",
    "    if regions_tool.file_type == \"gff\":\n",
    "        intersected[5] = intersected[shuffled_tool_field_count + 6]\n",
    "\n",
    "    values = intersected.apply(lambda x: \"\\t\".join([str(item) for item in list(x.name) + list(x[:shuffled_tool_field_count - 4])]), axis=1).values\n",
    "    new_bedtool = pybedtools.BedTool(\"\\n\".join(values), from_string=True)\n",
    "    return new_bedtool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_to_regions(tool, clusters=None, assigned_dir=\".\", species=\"hg19\", nrand=3):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Assigns each cluster to a genic region\n",
    "    finally saves all generated bed and fasta files for future analysis...\n",
    "\n",
    "    tool - a bed tool (each line represnting a cluster)\n",
    "    clusters - name of cluster file (optional)\n",
    "    assigned_dir - location to save files in\n",
    "    species - str species to segment\n",
    "    nrand - int number offsets times to shuffle for null hypothesis\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    if clusters is None:\n",
    "        clusters, ext = os.path.splitext(os.path.basename(tool.fn))\n",
    "    bedtracks = {}\n",
    "\n",
    "    regions, assigned_regions = CLIP_analysis.regions_generator()\n",
    "\n",
    "    for region in regions:\n",
    "        bedtracks[region] = pybedtools.BedTool(os.path.join(clipper.data_dir(), \"regions\", \"%s_%s.bed\" % (species,\n",
    "                                                                                                          region)))\n",
    "              \n",
    "    #creates the basics of bed dict\n",
    "    bed_dict = {'all': {'rand': {}}}\n",
    "\n",
    "    remaining_clusters = tool\n",
    "\n",
    "    # print \"There are a total %d clusters I'll examine\" % (len(tool))\n",
    "    for region in regions:\n",
    "        remaining_clusters, overlapping = intersection(remaining_clusters, b=bedtracks[region])\n",
    "\n",
    "        #if for some reason there isn't a peak in the region skip it\n",
    "        if len(overlapping) == 0:\n",
    "            # print \"ignoring %s \" % region\n",
    "            continue\n",
    "\n",
    "        #sets up bed dict for this region\n",
    "        bed_dict[region] = {'real': overlapping.sort(stream=True).saveas(),\n",
    "                            'rand': {}}\n",
    "\n",
    "        no_overlapping_count = len(remaining_clusters)\n",
    "        overlapping_count = len(bed_dict[region]['real'])\n",
    "        print \"For region: %s found %d that overlap and %d that don't\" % (region,\n",
    "                                                                          overlapping_count,\n",
    "                                                                          no_overlapping_count)\n",
    "\n",
    "        if 'real' not in bed_dict['all']:\n",
    "            bed_dict['all']['real'] = bed_dict[region]['real']\n",
    "        else:\n",
    "            bed_dict['all']['real'] = bed_dict['all']['real'].cat(bed_dict[region]['real'], stream=True, postmerge=False).saveas()\n",
    "\n",
    "        #saves offsets so after shuffling the offsets can be readjusted\n",
    "        for i in range(nrand):\n",
    "            random_intervals = bed_dict[region]['real'].shuffle(genome=species, incl=bedtracks[region].fn).sort()\n",
    "            random_intervals = fix_shuffled_strand(random_intervals, bedtracks[region].fn)\n",
    "            bed_dict[region]['rand'][i] = random_intervals.saveas()\n",
    "\n",
    "            if i not in bed_dict['all']['rand']:\n",
    "                bed_dict['all']['rand'][i] = bed_dict[region]['rand'][i]\n",
    "            else:\n",
    "                bed_dict['all']['rand'][i] = bed_dict['all']['rand'][i].cat(bed_dict[region]['rand'][i], stream=True, postmerge=False)\n",
    "\n",
    "        #if there are no more clusters to assign stop trying\n",
    "        if no_overlapping_count == 0:\n",
    "            break\n",
    "\n",
    "    # print \"After assigning %d un-categorized regions\" % len(remaining_clusters)\n",
    "\n",
    "    if len(remaining_clusters) > 0:\n",
    "        bed_dict['uncatagorized'] = {'real': remaining_clusters.sort(stream=True).saveas()}\n",
    "\n",
    "    bed_dict = save_bedtools(bed_dict, clusters, assigned_dir)\n",
    "    return bed_dict\n",
    "\n",
    "def save_bedtools(cluster_regions, clusters, assigned_dir):\n",
    "    \"\"\"\n",
    "    Given cluster regions file saves all bedtools sanely and returns result\n",
    "    :param cluster_regions:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for region in cluster_regions:\n",
    "        output_file = \"%s.%s.real.BED\" % (clusters, region)\n",
    "        cluster_regions[region]['real'] = cluster_regions[region]['real'].sort().saveas(os.path.join(assigned_dir, output_file))\n",
    "\n",
    "        if \"rand\" not in cluster_regions[region]:\n",
    "            continue\n",
    "\n",
    "        for n_rand in cluster_regions[region]['rand']:\n",
    "            output_file = \"%s.%s.rand.%s.BED\" % (clusters, region, n_rand)\n",
    "            cluster_regions[region]['rand'][n_rand] = cluster_regions[region]['rand'][n_rand].sort().saveas(os.path.join(assigned_dir, output_file))\n",
    "\n",
    "    return cluster_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genes = pybedtools.BedTool(\"/nas3/gpratt/clipper/clipper/data/regions/mm9_genes.bed\")\n",
    "\n",
    "rbps = {\"ggaatg_motif\": pybedtools.BedTool(\"ggtaagt.bed\")}\n",
    "\n",
    "for name, rbp in rbps.items():\n",
    "    overlapping_genes = rbp.intersect(genes, wo=True, s=True).each(move_name).saveas()\n",
    "    cluster_regions = assign_to_regions(overlapping_genes, \"ggaatg_taf15_motif\", \"assigned\", nrand=10, species=\"mm9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real = cluster_regions['all']['real']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "slopped_tool = real.slop(b=250, g=\"/nas3/yeolab/Genome/ucsc/mm9/mm9.chrom.sizes\")\n",
    "overlapping_count_df = slopped_tool.intersect(real, c=True, s=True).to_dataframe(names=['chrom', \n",
    "                                                                 'start', \n",
    "                                                                 'stop', \n",
    "                                                                 'name', \n",
    "                                                                 'score',\n",
    "                                                                 'strand',\n",
    "                                                                 \"chrom2\",\n",
    "                                                                 'start2',\n",
    "                                                                 'stop2',\n",
    "                                                                 'name2',\n",
    "                                                                 'score2',\n",
    "                                                                 'strand2',\n",
    "                                                                 'something',\n",
    "                                                                 'num_overlapping_targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for val, rand in cluster_regions['all']['rand'].items():\n",
    "    slopped_tool = rand.slop(b=250, g=\"/nas3/yeolab/Genome/ucsc/mm9/mm9.chrom.sizes\")\n",
    "\n",
    "    result[val] = slopped_tool.intersect(rand, c=True, s=True).to_dataframe(names=['chrom', \n",
    "                                                                 'start', \n",
    "                                                                 'stop', \n",
    "                                                                 'name', \n",
    "                                                                 'score',\n",
    "                                                                 'strand',\n",
    "                                                                 \"chrom2\",\n",
    "                                                                 'start2',\n",
    "                                                                 'stop2',\n",
    "                                                                 'name2',\n",
    "                                                                 'score2',\n",
    "                                                                 'strand2',\n",
    "                                                                 'something',\n",
    "                                                                 'num_overlapping_targets'])\n",
    "    \n",
    "result = pd.concat(result, names=['trial', 'motif_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real = (overlapping_count_df.num_overlapping_targets - 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.num_overlapping_targets = result.num_overlapping_targets - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rand = result.groupby(level=\"trial\").num_overlapping_targets.mean().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "scipy.stats.poisson.sf(real , rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
