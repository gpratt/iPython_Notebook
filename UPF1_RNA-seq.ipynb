{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "import pandas as pd\n",
      "import pysam\n",
      "import scipy.cluster\n",
      "import scipy.spatial\n",
      "import scipy.stats\n",
      "\n",
      "from sklearn import decomposition\n",
      "from scipy.stats import pearsonr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def rsquared(x, y):\n",
      "    \"\"\" Return R^2 where x and y are array-like.\"\"\"\n",
      "\n",
      "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y)\n",
      "    return r_value**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_rsq(df1, df2):\n",
      "    count = 0\n",
      "    figsize(10,10)\n",
      "    for x in range(len(df1.index.levels[0])):\n",
      "        for y in range(len(df2.index.levels[0])):\n",
      "            count += 1\n",
      "            subplot(len(df1.index.levels[0]),len(df2.index.levels[0]), count)\n",
      "            \n",
      "            combined = pd.concat([df1.RPKM[df1.index.levels[0][x]], df2.RPKM[df2.index.levels[0][y]]], \n",
      "                           join=\"inner\", axis=1, keys=['first', 'second'])\n",
      "            \n",
      "            \n",
      "            loglog(combined['first'], combined['second'], 'o', alpha=.05)\n",
      "            rsq = rsquared(combined['first'], combined['second'])\n",
      "            pearson = pearsonr(combined['first'], combined['second'])\n",
      "\n",
      "            title(\" \".join(map(str, [x, y, rsq, \"\\n\", pearson[0]])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/nas3/gpratt/projects/upf1/data/\"\n",
      "bams = \"\"\"318_UPF11_NoIndex_L004_R1.fastq.Aligned.out.sam.bam.sorted.bam  \n",
      "319_UPF12_NoIndex_L005_R1.fastq.Aligned.out.sam.bam.sorted.bam  \n",
      "320_UPF13_NoIndex_L006_R1.fastq.Aligned.out.sam.bam.sorted.bam  \n",
      "321_Luc1_NoIndex_L007_R1.fastq.Aligned.out.sam.bam.sorted.bam   \n",
      "322_Luc2_NoIndex_L008_R1.fastq.Aligned.out.sam.bam.sorted.bam\n",
      "323_Luc3_NoIndex_L001_R1.fastq.Aligned.out.sam.bam.sorted.bam\"\"\".strip().split()\n",
      "\n",
      "bam_dict = {name.split(\".\")[0] : pysam.Samfile(path + name) for name in bams}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "info_dict = {'mapped' : {}, 'unmapped' : {}}\n",
      "for name, bam in bam_dict.items():\n",
      "    info_dict['mapped'][name] = bam.mapped\n",
      "    info_dict['unmapped'][name] = bam.unmapped\n",
      "\n",
      "x =pd.DataFrame(info_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(x.to_html(formatters=[lambda x: \"{:,}\".format(x), lambda x: \"{:,}\".format(x)], justify=\"left\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: left;\">\n",
        "      <th></th>\n",
        "      <th>mapped</th>\n",
        "      <th>unmapped</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>318_UPF11_NoIndex_L004_R1</th>\n",
        "      <td>281,513,132</td>\n",
        "      <td>20,841,977</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>319_UPF12_NoIndex_L005_R1</th>\n",
        "      <td>248,242,511</td>\n",
        "      <td>37,545,897</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>320_UPF13_NoIndex_L006_R1</th>\n",
        "      <td>244,457,106</td>\n",
        "      <td>32,643,501</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>321_Luc1_NoIndex_L007_R1</th>\n",
        "      <td>300,231,123</td>\n",
        "      <td>23,340,514</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>322_Luc2_NoIndex_L008_R1</th>\n",
        "      <td>213,704,725</td>\n",
        "      <td>60,127,319</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>323_Luc3_NoIndex_L001_R1</th>\n",
        "      <td>217,705,722</td>\n",
        "      <td>27,244,994</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<IPython.core.display.HTML at 0x6768790>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "control_dfs = {control.split(\".\")[0] : pd.read_csv(path + control, sep=\"\\t\", index_col=0, na_values=[\"na\"]) for control in controls}\n",
      "control_dfs = pd.concat(control_dfs.values(), keys=control_dfs.keys(), names=['experiment', 'gene']).dropna()\n",
      "\n",
      "knockdown_dfs = {knockdown.split(\".\")[0] : pd.read_csv(path + knockdown, sep=\"\\t\", index_col=0, na_values=[\"na\"]) for knockdown in knockdowns}\n",
      "knockdown_dfs = pd.concat(knockdown_dfs.values(), keys=knockdown_dfs.keys(), names=['experiment', 'gene']).dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'controls' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-34ee63e4ecda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcontrol_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcontrol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"na\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcontrol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcontrol_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontrol_dfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontrol_dfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'experiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gene'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mknockdown_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mknockdown\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mknockdown\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"na\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mknockdown\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mknockdowns\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mknockdown_dfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mknockdown_dfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mknockdown_dfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'experiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gene'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'controls' is not defined"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "controls = \"\"\"318_UPF11_NoIndex_L004_R1.fastq.Aligned.out.sam.bam.sorted.bam.rpkm  \n",
      "319_UPF12_NoIndex_L005_R1.fastq.Aligned.out.sam.bam.sorted.bam.rpkm \n",
      "320_UPF13_NoIndex_L006_R1.fastq.Aligned.out.sam.bam.sorted.bam.rpkm\"\"\".strip().split()\n",
      "\n",
      "knockdowns = \"\"\"321_Luc1_NoIndex_L007_R1.fastq.Aligned.out.sam.bam.sorted.bam.rpkm  \n",
      "322_Luc2_NoIndex_L008_R1.fastq.Aligned.out.sam.bam.sorted.bam.rpkm\n",
      "323_Luc3_NoIndex_L001_R1.fastq.Aligned.out.sam.bam.sorted.bam.rpkm\"\"\".strip().split()\n",
      "\n",
      "steph_controls = \"\"\"control-nosquish.rnaseq.293t.1.1.trimmed.norep_gsnaphg19.srt.bam.rpkm  control-nosquish.rnaseq.293t.5.1.trimmed.norep_gsnaphg19.srt.bam.rpkm\n",
      "control-nosquish.rnaseq.293t.2.1.trimmed.norep_gsnaphg19.srt.bam.rpkm  \n",
      "control-nosquish.rnaseq.293t.3.1.trimmed.norep_gsnaphg19.srt.bam.rpkm \n",
      "control-nosquish.rnaseq.293t.4.1.trimmed.norep_gsnaphg19.srt.bam.rpkm\"\"\".strip().split()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/nas3/gpratt/projects/upf1/data/\"\n",
      "control_dfs_dict = {control.split(\".\")[0] : pd.read_csv(path + control, sep=\"\\t\", index_col=0, na_values=[\"na\"]) for control in controls}\n",
      "control_dfs = pd.concat(control_dfs_dict.values(), keys=control_dfs_dict.keys(), names=['experiment', 'gene']).dropna()\n",
      "\n",
      "knockdown_dfs_dict = {knockdown.split(\".\")[0] : pd.read_csv(path + knockdown, sep=\"\\t\", index_col=0, na_values=[\"na\"]) for knockdown in knockdowns}\n",
      "knockdown_dfs = pd.concat(knockdown_dfs_dict.values(), keys=knockdown_dfs_dict.keys(), names=['experiment', 'gene']).dropna()\n",
      "\n",
      "path = \"/nas3/shuelga/projects/hnrnp_ncrna/rnaseq_hg19/gene_expression/\"\n",
      "steph_controls_dfs_dict = {\".\".join(steph_control.split(\".\")[0:4]) : pd.read_csv(path + steph_control, sep=\"\\t\", index_col=0, na_values=[\"na\"]) for steph_control in steph_controls}\n",
      "steph_controls_dfs = pd.concat(steph_controls_dfs_dict.values(), keys=steph_controls_dfs_dict.keys(), names=['experiment', 'gene']).dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_dfs = pd.concat(control_dfs_dict.values() + knockdown_dfs_dict.values() + steph_controls_dfs_dict.values(), \n",
      "                    keys=control_dfs_dict.keys() + knockdown_dfs_dict.keys() + steph_controls_dfs_dict.keys(), \n",
      "                    names=['experiment', 'gene']).dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/nas3/gpratt/projects/upf1/analysis/rna_seq/all_rpkms/\"\n",
      "df_t = pd.read_csv(path + \"all.txt\", sep=\"\\t\", index_col=0, na_values=[\"na\"]).transpose()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_rsq(control_dfs, control_dfs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_rsq(knockdown_dfs, knockdown_dfs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_rsq(knockdown_dfs, control_dfs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corr_dict = {}\n",
      "for dataset1 in all_dfs.index.levels[0]:\n",
      "    corr_dict[dataset1] = {}\n",
      "    for dataset2 in all_dfs.index.levels[0]:\n",
      "        x = pd.merge(all_dfs.ix[dataset1][all_dfs.ix[dataset1].flag == 0],\n",
      "                   all_dfs.ix[dataset2][all_dfs.ix[dataset2].flag == 0], left_index=True, right_index=True, how='inner')\n",
      "        #print dataset1, len(x.RPKM_x), dataset2, len(x.RPKM_y)\n",
      "        \n",
      "        corr_dict[dataset1][dataset2] = rsquared(x.RPKM_x, x.RPKM_y)\n",
      "\n",
      "corr_dict = pd.DataFrame(corr_dict)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(6,6)\n",
      "y_events = scipy.spatial.distance.pdist(corr_dict)\n",
      "Z_events = scipy.cluster.hierarchy.linkage(y_events)\n",
      "d_events = scipy.cluster.hierarchy.dendrogram(Z_events, orientation='right', distance_sort='descending', no_labels=True)\n",
      "event_order = d_events['leaves'][::-1]\n",
      "title(\"clustering of samples by jacard correlation\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(6,6)\n",
      "matshow(corr_dict.as_matrix()[event_order,:][:,event_order], interpolation=\"nearest\")\n",
      "yticks(arange(len(corr_dict.index)), [ corr_dict.index[i] for i in event_order] )\n",
      "xticks(arange(len(corr_dict.columns)) + .5,[ corr_dict.columns[i] for i in event_order] , rotation=45)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = all_dfs[all_dfs.flag == 0].dropna()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.index.levels[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(x_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(10,10)\n",
      "# convert from pandas to numpy array\n",
      "df_array = df_t.as_matrix()\n",
      "#values = df_array\n",
      "values = log(df_array)\n",
      "print shape(values)\n",
      "\n",
      "# PCA\n",
      "pca = decomposition.PCA(whiten=True, n_components=3)\n",
      "pca.fit(values)\n",
      "X=pca.transform(values)\n",
      "\n",
      "gene_ids = df_t.index\n",
      "print gene_ids\n",
      "\n",
      "# scale for component vectors\n",
      "c_scale = 2700\n",
      "\n",
      "print shape(pca.components_)\n",
      "(comp_x, comp_y) = (pca.components_[0,:], pca.components_[1,:])\n",
      "\n",
      "print shape(comp_x)\n",
      "print shape(comp_y)\n",
      "print shape(gene_ids)\n",
      "\n",
      "# using two kinds of distance measurement\n",
      "dist_list_L1 = []\n",
      "dist_list_L2 = []\n",
      "for (x, y, gene_id) in zip(comp_x, comp_y, gene_ids):\n",
      "\n",
      "    x = x*c_scale\n",
      "    y = y*c_scale\n",
      "    \n",
      "    try:\n",
      "        dist_list_L1.append((x, y, annot_dict[gene_id], abs(y)+abs(x)))\n",
      "        dist_list_L2.append((x, y, annot_dict[gene_id], math.sqrt((y**2)+(x**2))))\n",
      "    except:\n",
      "        dist_list_L1.append((x, y, gene_id, abs(y)+abs(x)))\n",
      "        dist_list_L2.append((x, y, gene_id, math.sqrt((y**2)+(x**2))))\n",
      "\n",
      "# plotting\n",
      "fig = matplotlib.pyplot.figure(figsize=(10,10))\n",
      "x_list = X[:, 0]\n",
      "y_list = X[:, 1]\n",
      "\n",
      "# colors array and names array was defined above\n",
      "\n",
      "zipped_list = zip(x_list, y_list, df_t.index)\n",
      "\n",
      "for (x, y, marker) in zipped_list:\n",
      "    scatter(x, y)\n",
      "\n",
      "print \"L1\"\n",
      "for item in sorted(dist_list_L1, key=lambda item: item[3], reverse=True)[:40]:\n",
      "    print \"\\t\".join([str(item[0]), str(item[1]), str(item[2]), str(item[3])])\n",
      "    \n",
      "    plot([0, item[0]], [0, item[1]], c='black')\n",
      "    text(item[0], item[1], item[2], color='black')\n",
      "\n",
      "print\n",
      "print \"L2\"\n",
      "for item in sorted(dist_list_L2, key=lambda item: item[3], reverse=True)[:40]:\n",
      "\n",
      "    print \"\\t\".join([str(item[0]), str(item[1]), str(item[2]), str(item[3])])\n",
      "\n",
      "    plot([0, item[0]], [0, item[1]], c='purple')\n",
      "    text(item[0], item[1], item[2], color='purple')     \n",
      " \n",
      "\n",
      "\n",
      "xlabel('1st Principal Component', size=20)\n",
      "ylabel('2nd Principal Component', size=20)\n",
      "title('PCA', size=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}