{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "import os\n",
      "import pickle\n",
      "import glob\n",
      "\n",
      "import matplotlib.ticker as tkr\n",
      "from IPython.core.display import HTML\n",
      "import pandas as pd\n",
      "import scipy.spatial\n",
      "import scipy.cluster\n",
      "\n",
      "from gscripts.general import parsers\n",
      "from gscripts.general.dataviz import Figure\n",
      "from gscripts.GO import GO\n",
      "import gffutils\n",
      "from scipy.stats import hypergeom\n",
      "\n",
      "img_path = \"/nas3/gpratt/Dropbox/Presentations/notebooks/public_clip\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Exception in thread Thread-2:\n",
        "Traceback (most recent call last):\n",
        "  File \"/nas3/yeolab/Software/Python-2.7.5/lib/python2.7/threading.py\", line 808, in __bootstrap_inner\n",
        "    self.run()\n",
        "  File \"/nas3/yeolab/Software/Python-2.7.5/lib/python2.7/site-packages/IPython/kernel/zmq/heartbeat.py\", line 55, in run\n",
        "    zmq.device(zmq.FORWARDER, self.socket, self.socket)\n",
        "  File \"_device.pyx\", line 52, in zmq.core._device.device (zmq/core/_device.c:1040)\n",
        "  File \"_device.pyx\", line 82, in zmq.core._device.proxy (zmq/core/_device.c:1325)\n",
        "  File \"checkrc.pxd\", line 21, in zmq.core.checkrc._check_rc (zmq/core/_device.c:1562)\n",
        "ZMQError: Interrupted system call\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Helper functions"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def commas(x, pos):\n",
      "    try:\n",
      "        return \"{:,}\".format(int(x))\n",
      "    except:\n",
      "        return \"0\"\n",
      "    \n",
      "def percent(x, pos):\n",
      "    return str(float(x) * 100)  + \"%\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Make Analysis Dataframes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clip_rnaseq_df = parsers.clipseq_metrics(\"/nas3/gpratt/projects/public_clip/analysis/v3/\")\n",
      "public_clip_list = pd.read_csv(\"/nas3/gpratt/projects/public_clip/v1/public_clip_list.csv\", index_col=0)\n",
      "clip_rnaseq_df = pd.merge(clip_rnaseq_df, public_clip_list, left_index=True, right_index=True, how=\"outer\")\n",
      "clip_df = clip_rnaseq_df[clip_rnaseq_df['CLIP-seq?'] == \"Yes\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "global name 'spot_names' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-84d856f76248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclip_rnaseq_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclipseq_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/nas3/gpratt/projects/public_clip/analysis/v3/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpublic_clip_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/nas3/gpratt/projects/public_clip/v1/public_clip_list.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclip_rnaseq_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_rnaseq_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpublic_clip_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"outer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mclip_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_rnaseq_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclip_rnaseq_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'CLIP-seq?'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"Yes\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/nas/nas0/gpratt/gscripts/gscripts/general/parsers.pyc\u001b[0m in \u001b[0;36mclipseq_metrics\u001b[1;34m(analysis_dir, iclip, sep)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mrm_duped_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mparse_rm_duped_metrics_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrm_duped_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrm_duped_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrm_duped_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mspot_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mparse_peak_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspot_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspot_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mspot_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mpeaks_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"Num Peaks\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpybedtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBedTool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeaks_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeaks_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpeaks_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mcombined_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnaseq_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalysis_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_seps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: global name 'spot_names' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis_dir = \"/nas3/gpratt/projects/public_encode/\"\n",
      "encode_df = pd.read_csv(os.path.join(analysis_dir, \"ENCODE Data Quality Metrics 2012-04-25.csv\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis_dir = \"/nas3/gpratt/projects/public_clip/analysis/public_iclip_v1/\"\n",
      "public_iclip_df = parsers.clipseq_metrics(analysis_dir, iclip=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "analysis_dir = \"/nas3/gpratt/projects/encode/analysis/v7\"\n",
      "iclip_df = parsers.clipseq_metrics(analysis_dir, iclip=True)\n",
      "true_iclips = iclip_df[[\"IMP\" in idx.split(\".\")[1] for idx in iclip_df.index]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Plot Comparisons"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with Figure(os.path.join(img_path, \"usable_reads_boxplot.svg\"), figsize=(7,5)) as fig:\n",
      "    ax = fig.add_subplot(111)\n",
      "    ax.boxplot([encode_df['N_uniq map reads'].apply(lambda x: x.replace(\",\", \"\")).astype(int), \n",
      "               clip_df['Usable Reads'].dropna(), \n",
      "               public_iclip_df['Usable Reads'],\n",
      "               true_iclips['Usable Reads'], \n",
      "               \n",
      "               ])\n",
      "    y_format = tkr.FuncFormatter(commas)  # make formatter\n",
      "    ax.yaxis.set_major_formatter(y_format)\n",
      "    ax.set_title(\"Average Number of Usable Reads\")\n",
      "    ax.set_ylabel(\"Usable Reads\")\n",
      "    \n",
      "    ax.set_xticklabels([\"ENCODE\\nChIP\", \"Public\\nCLIP\", \"Public\\niCLIP\", \"ENCODE\\niCLIP\"]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mean(encode_df['N_uniq map reads'].apply(lambda x: x.replace(\",\", \"\")).astype(int)),\n",
      "print mean(clip_df['Usable Reads'].dropna()), \n",
      "print mean(public_iclip_df['Usable Reads']),\n",
      "print mean(true_iclips['Usable Reads'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print median(encode_df['N_uniq map reads'].apply(lambda x: x.replace(\",\", \"\")).astype(int)),\n",
      "print median(clip_df['Usable Reads'].dropna()), \n",
      "print median(public_iclip_df['Usable Reads']),\n",
      "print median(true_iclips['Usable Reads'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with Figure(os.path.join(img_path, \"percent_reads_remaining.svg\"), figsize=(7,7)) as fig:\n",
      "    ax = fig.add_subplot(111)\n",
      "    ax.boxplot([public_iclip_df['Usable Reads'].astype(float) / public_iclip_df['Uniquely mapped reads number'].astype(float),\n",
      "                true_iclips['Usable Reads'].astype(float) / true_iclips['Uniquely mapped reads number'].astype(float), \n",
      "                ])\n",
      "\n",
      "    y_format = tkr.FuncFormatter(percent)  # make formatter\n",
      "    ax.yaxis.set_major_formatter(y_format)\n",
      "    ax.set_title(\"Percent Reads Remaining\\nAfter Duplicate Removal\")\n",
      "    ax.set_ylabel(\"Percent Reads Remainig\")\n",
      "    \n",
      "    ax.set_xticklabels([\"Public\\niCLIP\", \"ENCODE\\niCLIP\"]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with Figure(os.path.join(img_path, \"percent_of_total.svg\"), figsize=(7,7)) as fig:\n",
      "    ax = fig.add_subplot(111)\n",
      "    ax.boxplot([clip_df['Usable Reads'] / clip_df['Processed reads'], \n",
      "               public_iclip_df['Usable Reads'] / public_iclip_df['Processed reads'],\n",
      "               iclip_df['Usable Reads'] / iclip_df['Processed reads']])\n",
      "    ax.set_title(\"Percent Usable of Total Reads\")\n",
      "    y_format = tkr.FuncFormatter(percent)  # make formatter\n",
      "    ax.yaxis.set_major_formatter(y_format)\n",
      "    ax.set_ylabel(\"Percent\")\n",
      "    ax.set_xticklabels([\"Public\\n CLIP\", \"Public\\niCLIP\", \"ENCODE\\niCLIP\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with Figure(os.path.join(img_path, \"clip_pcr_duplication.svg\"), figsize=(7,7)) as fig:\n",
      "    ax = fig.add_subplot(1,1,1)\n",
      "    ax.boxplot([encode_df.PBC, clip_df.PCB.dropna(), public_iclip_df.PCB.dropna(), iclip_df.PCB.dropna()])\n",
      "    ax.set_title(\"PCR Bottleneck Coefficient\")\n",
      "    ax.set_ylabel(\"PBC\")\n",
      "    ax.set_xticklabels([\"ENCODE\\nChIP-seq\", \"Public\\nCLIP-seq\", \"Public\\niCLIP\", \"ENCODE\\niCLIP\"])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "public_iclip_df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with Figure(os.path.join(img_path, \"Sequenced_Reads_vs_usable_Reads.svg\"), figsize=(8,8)) as fig:\n",
      "    ax = fig.add_subplot(1,1,1)\n",
      "    ax.scatter(true_iclips['Processed reads'] / 1000000, true_iclips['Usable Reads'] /1000000)\n",
      "    y_format = tkr.FuncFormatter(commas)  # make formatter\n",
      "    ax.yaxis.set_major_formatter(y_format)\n",
      "    ax.xaxis.set_major_formatter(y_format)\n",
      "    ax.set_ylabel(\"Usable Reads (Millions)\")\n",
      "    ax.set_xlabel(\"Sequenced Reads (Millions)\")\n",
      "    ax.set_title(\"Sequenced Reads vs Usable Reads\")\n",
      "    ax.set_ylim((0,100))\n",
      "    ax.set_xlim((0,100))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print scipy.stats.scoreatpercentile(public_iclip_df['Usable Reads'], per=[20, 50, 90, 100])\n",
      "print scipy.stats.scoreatpercentile(true_iclips['Usable Reads'].dropna(), per=[20, 50, 90, 100])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hek_293_df = clip_df[(clip_df['Cell Type'] == 'HEK 293') | (clip_df['Cell Type'] == '293T') | (clip_df['Cell Type'] == 'FlpIn T-Rex HEK 293')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(clip_df[clip_df.Antibody == \"hnRNPA2B1\"].to_html())MDAMB231_hnRNPA2B1_WT_rep1.peaks.bed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(hek_293_df[hek_293_df['Antibody'] == 'Ago2'].to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ago2_beds = [\"SRR189782.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\",\n",
      "\"SRR189783.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\",\n",
      "\"SRR189784.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\",\n",
      "\"SRR189785.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\",\n",
      "\"SRR189786.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\",\n",
      "\"SRR189787.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\"]\n",
      "\n",
      "ago2_beds = {bed : pybedtools.BedTool(bed) for bed in ago2_beds}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fox2_beds = !ls /nas3/gpratt/projects/fox2_iclip/*.bed\n",
      "fox2_beds = {bed : pybedtools.BedTool(bed) for bed in fox2_beds}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for ago2_name, ago2_bed in ago2_beds.items():\n",
      "    for fox2_name, fox2_bed in fox2_beds.items():\n",
      "        print ago2_name, fox2_name, len(ago2_bed.intersect(fox2_bed, u=True))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = pybedtools.BedTool()\n",
      "result = x.multi_intersect(i=[srr + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\" for srr in list(hek_293_df.index)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = clip_df.groupby(['Species', 'Cell Type', 'Antibody'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foo = x.size()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(clip_df[clip_df['Antibody'] == \"IGF2BP3 (anti-flag)\"].to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "foo.to_csv(img_path + \"processed_list.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "merged_tools = {}\n",
      "for name, group in hek_293_df.groupby(\"Antibody\"):\n",
      "    a = pybedtools.BedTool()\n",
      "    bedtools = \" \".join([srr + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\" for srr in list(group.index)])\n",
      "    out_name = name.split()[0] + \".bed\"\n",
      "    !cat $bedtools | mergeBed -s -nms -i - > $out_name\n",
      "    merged_tools[name.split()[0] ] = pybedtools.BedTool(out_name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tools = [pybedtools.BedTool(srr + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\") for srr in list(hek_293_df.index)]\n",
      "intersections = {}\n",
      "unions = {}\n",
      "jaccard = {}\n",
      "for x1, (bed_1_name, bed_1) in enumerate(merged_tools.items()):\n",
      "    intersections[bed_1_name] = {}\n",
      "    unions[bed_1_name] = {}\n",
      "    jaccard[bed_1_name] = {}\n",
      "    for x2, (bed_2_name, bed_2) in enumerate(merged_tools.items()):\n",
      "\n",
      "        intersect = !intersectBed -a $bed_1.fn -b $bed_2.fn -u | wc -l\n",
      "        union = !cat $bed_1.fn $bed_2.fn | sort -k1,1 -k2,2n  | mergeBed  | wc -l \n",
      "\n",
      "        intersect_count = int(intersect[0].split()[0])\n",
      "        union_count = int(union[0].split()[0])\n",
      "        jaccard_score = intersect_count / float(union_count)\n",
      "        unions[bed_1_name][bed_2_name] = intersect_count\n",
      "        intersections[bed_1_name][bed_2_name] = intersect_count\n",
      "        jaccard[bed_1_name][bed_2_name] = jaccard_score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hist([len(bedtool) for bedtool in tools], range=(0,5000), bins=100) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickled_files = !ls *.pickleimport itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"cytoscape_out.csv\", 'w') as cytoscape_out:\n",
      "    for bed_1, bed_2 in itertools.combinations(jaccard.keys(), 2):\n",
      "        cytoscape_out.write(\",\".join([bed_1, bed_2, str(jaccard[bed_1][bed_2])]) + \"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'itertools' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-4-a83c90d02495>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cytoscape_out.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcytoscape_out\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbed_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbed_2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombinations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mcytoscape_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbed_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbed_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbed_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbed_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'itertools' is not defined"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_events = scipy.spatial.distance.pdist(normalized_regions)\n",
      "Z_events = scipy.cluster.hierarchy.linkage(y_events)\n",
      "d_events = scipy.cluster.hierarchy.dendrogram(Z_events, orientation='right', distance_sort='descending', no_labels=True)\n",
      "event_order = d_events['leaves'][::-1]\n",
      "\n",
      "matshow(normalized_regions.as_matrix()[event_order,:][:,:], interpolation=\"nearest\", cmap=cm.gist_yarg)\n",
      "yticks(arange(len(normalized_regions.index)), [ all_names[i] for i in event_order] )\n",
      "xticks(arange(len(normalized_regions.columns)) + .2,[ normalized_regions.columns[i] for i in range(len(normalized_regions.columns))] , rotation=45)\n",
      "\n",
      "colorbar()fixed_df = combined_df.dropna()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "SyntaxError",
       "evalue": "invalid syntax (<ipython-input-5-2fb19e440917>, line 10)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-2fb19e440917>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    colorbar()fixed_df = combined_df.dropna()\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run saturation analysis on a few highly sequenced datasets, other public ones NOVA? TBP43? FOX2? fuck it, all of em"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"downsample.txt\", 'w') as out_file:\n",
      "    for row in combined_df.iterrows():\n",
      "        out_file.write(\"\\t\".join([\"/home/gpratt/projects/public_clip/analysis/v1/\" + row[0] + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.bam\", row[1][\"Species\"]]) + \"\\n\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'combined_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-a33f657faf15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"downsample.txt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mout_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"/home/gpratt/projects/public_clip/analysis/v1/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.bam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Species\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'combined_df' is not defined"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickled_files = !ls *.pickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pickled_names = [pickled_file.split(\".\")[0] for pickled_file in pickled_files]\n",
      "all_names = [\"_\".join(list(combined_df.ix[pickled_name][['Cell Type', 'Antibody']])) for pickled_name in pickled_names]\n",
      "pickled_data = [pickle.load(open(pickled_file)) for pickled_file in pickled_files]\n",
      "region_sizes = {x : pickled_file['region_sizes'] for x, pickled_file in enumerate(pickled_data)}\n",
      "regions_df = pd.DataFrame(region_sizes).transpose()\n",
      "normalized_regions = regions_df.applymap(float).div(regions_df.sum(axis = 1), axis=\"index\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'combined_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-8-46d743c1c372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpickled_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpickled_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpickled_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpickled_files\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpickled_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Cell Type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Antibody'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpickled_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpickled_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpickled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpickled_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpickled_files\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mregion_sizes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpickled_file\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'region_sizes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickled_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpickled_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mregions_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'combined_df' is not defined"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_events = scipy.spatial.distance.pdist(normalized_regions)\n",
      "Z_events = scipy.cluster.hierarchy.linkage(y_events)\n",
      "d_events = scipy.cluster.hierarchy.dendrogram(Z_events, orientation='right', distance_sort='descending', no_labels=True)\n",
      "event_order = d_events['leaves'][::-1]\n",
      "\n",
      "matshow(normalized_regions.as_matrix()[event_order,:][:,:], interpolation=\"nearest\", cmap=cm.gist_yarg)\n",
      "yticks(arange(len(normalized_regions.index)), [ all_names[i] for i in event_order] )\n",
      "xticks(arange(len(normalized_regions.columns)) + .2,[ normalized_regions.columns[i] for i in range(len(normalized_regions.columns))] , rotation=45)\n",
      "\n",
      "colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'normalized_regions' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-9-ae91945e5911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_regions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mZ_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhierarchy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinkage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_events\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0md_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhierarchy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdendrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ_events\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'right'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'descending'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mevent_order\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md_events\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'leaves'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'normalized_regions' is not defined"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hek_293_genes = {name : [interval.name.split(\";\")[0].split(\".\")[0] for interval in bedtool] for name, bedtool in merged_tools.items()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'merged_tools' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-10-26161ef420e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhek_293_genes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minterval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbedtool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbedtool\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmerged_tools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'merged_tools' is not defined"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rowhg19GO = GO.hg19GO()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "type object 'GO' has no attribute 'hg19GO'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-11-307d56044a25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrowhg19GO\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhg19GO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mAttributeError\u001b[0m: type object 'GO' has no attribute 'hg19GO'"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hek_293_go_terms = {name : hg19GO.enrichment(genes) for name, genes in hek_293_genes.items()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'hek_293_genes' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-12-efc0b591e132>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhek_293_go_terms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mhg19GO\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menrichment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenes\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhek_293_genes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'hek_293_genes' is not defined"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hek_293_go_terms_df = pd.concat(hek_293_go_terms.values(), keys = hek_293_go_terms.keys(), names=['group', 'ontology'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'hek_293_go_terms' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-13-8bd1ccad6905>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhek_293_go_terms_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhek_293_go_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhek_293_go_terms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ontology'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mNameError\u001b[0m: name 'hek_293_go_terms' is not defined"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hek_293_go_terms_set = set([])\n",
      "for go_term in hek_293_go_terms_df.index.get_level_values('ontology'):\n",
      "    if sum(hek_293_go_terms_df.xs(go_term, level=\"ontology\")['Bonferroni-corrected Hypergeometric p-Value'] < .00001) > 1:\n",
      "        hek_293_go_terms_set.add(go_term)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'hek_293_go_terms_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-14-3766ecfa1a43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mhek_293_go_terms_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mgo_term\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhek_293_go_terms_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ontology'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhek_293_go_terms_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgo_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ontology\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bonferroni-corrected Hypergeometric p-Value'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m.00001\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mhek_293_go_terms_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgo_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'hek_293_go_terms_df' is not defined"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_col_names(dataframe):\n",
      "    \"\"\"\n",
      "    \n",
      "    Some names are null, this compresses them and returns a true list of go annotation names\n",
      "\n",
      "    \"\"\"\n",
      "    row_names = []\n",
      "    for row_name in dataframe[dataframe.columns[0]]:\n",
      "        row_names.append(row_name)\n",
      "    \n",
      "    for column_name in dataframe.columns[1:]:\n",
      "        try:\n",
      "            for x, row_name in enumerate(dataframe[column_name]):\n",
      "                if type(row_names[x]) is not str:\n",
      "                    row_names[x] = row_name\n",
      "        except:\n",
      "            pass\n",
      "    return row_names"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hek_293_go_terms_values = hek_293_go_terms_df.swaplevel(0,1).ix[hek_293_go_terms_set]['Bonferroni-corrected Hypergeometric p-Value'].unstack().fillna(1)\n",
      "hek_293_go_terms_col_names = list(hek_293_go_terms_df.swaplevel(0,1).ix[hek_293_go_terms_set]['GO Term Description'].unstack().columns)\n",
      "hek_293_go_terms_row_names = get_col_names(hek_293_go_terms_df.swaplevel(0,1).ix[hek_293_go_terms_set]['GO Term Description'].unstack())\n",
      "x = clusterGram(-1. * log10(matrix(hek_293_go_terms_values)), hek_293_go_terms_col_names, hek_293_go_terms_row_names )\n",
      "savefig(img_path + \"go_ontology.pdf\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'hek_293_go_terms_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-4799ead5a0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhek_293_go_terms_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhek_293_go_terms_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswaplevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhek_293_go_terms_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Bonferroni-corrected Hypergeometric p-Value'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhek_293_go_terms_col_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhek_293_go_terms_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswaplevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhek_293_go_terms_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GO Term Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhek_293_go_terms_row_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_col_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhek_293_go_terms_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswaplevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhek_293_go_terms_set\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'GO Term Description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclusterGram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhek_293_go_terms_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhek_293_go_terms_col_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhek_293_go_terms_row_names\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"go_ontology.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'hek_293_go_terms_df' is not defined"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "import matplotlib.gridspec as gridspec\n",
      "path = '/home/lovci/HelveticaLight.ttf'\n",
      "import matplotlib.font_manager as fm\n",
      "\n",
      "def clusterGram(data, colLabels, rowLabels, distance_metric = 'euclidean', linkage_method = 'average', \n",
      "             clusterRows=True, clusterCols=True, timeSeries=False, doCovar=False, realdata=None):\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    Run hierarchical clustering on data. Creates a heatmap of cluster-ordered data\n",
      "    heavy-lifting is done by:\n",
      "    \n",
      "    gets distances between rows/columns\n",
      "    \n",
      "    y_events = scipy.spatial.distance.pdist(data, distance_metric)\n",
      "\n",
      "    calculates the closest rows/columns\n",
      "\n",
      "    Z_events = scipy.cluster.hierarchy.linkage(y_events, linkage_method)\n",
      "\n",
      "    genereates dendrogram (tree)\n",
      "\n",
      "    d_events = scipy.cluster.hierarchy.dendrogram(Z_events, no_labels=True) \n",
      "    \n",
      "    set outfile == \"None\" to inibit saving an eps file (only show it, don't save it)\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    if clusterRows:\n",
      "        print \"getting row distance matrix\"\n",
      "        y_events = scipy.spatial.distance.pdist(data, distance_metric)\n",
      "        print \"calculating linkages\"\n",
      "        Z_events = scipy.cluster.hierarchy.linkage(y_events, linkage_method, metric=distance_metric)\n",
      "\n",
      "    if clusterCols:\n",
      "        print \"getting column distance matrix\"    \n",
      "        y_samples = scipy.spatial.distance.pdist(np.transpose(data), distance_metric)\n",
      "        print \"calculating linkages\"    \n",
      "        Z_samples = scipy.cluster.hierarchy.linkage(y_samples, linkage_method, metric=distance_metric)\n",
      "    else:\n",
      "        if doCovar:\n",
      "            raise ValueError\n",
      "\n",
      "    fig = pylab.figure(figsize=(8,30))\n",
      "\n",
      "    gs = gridspec.GridSpec(12,16)\n",
      "\n",
      "    ax1 = pylab.subplot(gs[1:11, 1:3])\n",
      "\n",
      "    ax1.set_xticks([])\n",
      "    ax1.set_yticks([])\n",
      "    ax1.set_axis_off()\n",
      "    nRow, nCol = data.shape\n",
      "    print \"nRow: %d\" %nRow\n",
      "    if realdata != None:\n",
      "        print realdata.shape\n",
      "        print data.shape\n",
      "\n",
      "        assert realdata.shape == data.shape\n",
      "\n",
      "        reordered = realdata\n",
      "    else:\n",
      "        reordered = data\n",
      "        \n",
      "    event_order = range(nRow)\n",
      "    if clusterRows:\n",
      "        d_events = scipy.cluster.hierarchy.dendrogram(Z_events, orientation='right', no_labels=True)\n",
      "        event_order = d_events['leaves']\n",
      "        reordered = reordered[event_order,:]\n",
      "        \n",
      "    ax2 = pylab.subplot(gs[0:1, 3:9])\n",
      "\n",
      "    ax2.set_xticks([])\n",
      "    ax2.set_yticks([])\n",
      "    ax2.set_axis_off()\n",
      "    sample_order = range(nCol)\n",
      "    if clusterCols:\n",
      "        d_samples = scipy.cluster.hierarchy.dendrogram(Z_samples, no_labels=True)    \n",
      "        sample_order = d_samples['leaves']\n",
      "        reordered = reordered[:,sample_order]\n",
      "    axmatrix = pylab.subplot(gs[1:11, 3:9])\n",
      "    bds = np.max(abs(reordered))\n",
      "    if timeSeries:\n",
      "        norm = mpl.colors.Normalize(vmin=-bds, vmax=bds)\n",
      "    else:\n",
      "        norm = None\n",
      "        \n",
      "\n",
      "    cmap = pylab.cm.bone_r\n",
      "        \n",
      "    im = axmatrix.matshow(reordered, aspect='auto', origin='lower', cmap=cmap, norm=norm)\n",
      "    axmatrix.set_xticks([])\n",
      "    axmatrix.yaxis.tick_right()\n",
      "    axmatrix.set_yticks(range(nRow))\n",
      "    axmatrix.set_yticklabels([rowLabels[i] for i in event_order], fontsize=16)\n",
      "    axcolor = pylab.subplot(gs[1:11, 0])\n",
      "\n",
      "    #\n",
      "    cbTicks = [np.min(data), np.mean(data), np.max(data)]\n",
      "    cb = pylab.colorbar(im, cax=axcolor, ticks=cbTicks, use_gridspec=True)\n",
      "    cb.ax.set_yticklabels(map(lambda x: \"%.2f\" %x, cbTicks))\n",
      "    axcolor.yaxis.tick_left()\n",
      "    #axRowLabel = pylab.subplot(gs[1:6, 9:13])\n",
      "    #print nRow\n",
      "\n",
      "\n",
      "    #axRowLabel.set_yticks(map(lambda x: x+.5, range(nRow)))\n",
      "        \n",
      "    \n",
      "    \n",
      "    axlabel = pylab.subplot(gs[11:, 3:9]) \n",
      "\n",
      "    step = 1./nCol\n",
      "    for i, ind in enumerate(sample_order):\n",
      "        xpos = (i*step)+(step/2)\n",
      "        pylab.text(xpos,1, colLabels[ind] , rotation=90,verticalalignment='top', horizontalalignment='center')\n",
      "    axlabel.set_xticks([])\n",
      "    axlabel.set_yticks([])\n",
      "    axlabel.set_axis_off()\n",
      "    \n",
      "    #    fig.show()\n",
      "    #pylab.tight_layout()\n",
      "\n",
      "    if doCovar:\n",
      "        cluster_covariance(data, colLabels, distance_metric = distance_metric, linkage_method = linkage_method)\n",
      "        \n",
      "    return event_order, sample_order"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "human_bw_pos = [x + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.pos.bw\" for x in clip_df[clip_df['Species'] == 'hg19'].index]\n",
      "human_bw_neg = [x + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.neg.bw\" for x in clip_df[clip_df['Species'] == 'hg19'].index]\n",
      "human_bb = [x + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.fixed.bb\" for x in clip_df[clip_df['Species'] == 'hg19'].index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'clip_df' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-18-c985a2196d60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhuman_bw_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.pos.bw\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclip_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclip_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Species'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'hg19'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhuman_bw_neg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.neg.bw\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclip_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclip_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Species'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'hg19'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhuman_bb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.fixed.bb\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclip_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclip_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Species'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'hg19'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'clip_df' is not defined"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Jasons request, finding genes with peaks in 3' UTR of given genes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "utr3_regions = pybedtools.BedTool(\"/nas3/gpratt/clipper/clipper/data/regions/utr3.hg19.bed\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "File \"/nas3/gpratt/clipper/clipper/data/regions/utr3.hg19.bed\" does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-19-7db8d95ee4dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mutr3_regions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpybedtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBedTool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/nas3/gpratt/clipper/clipper/data/regions/utr3.hg19.bed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m/nas3/yeolab/Software/Python-2.7.5/lib/python2.7/site-packages/pybedtools-0.6.2-py2.7-linux-x86_64.egg/pybedtools/bedtool.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fn, from_string)\u001b[0m\n\u001b[0;32m    364\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'File \"%s\" does not exist'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_isbam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misBAM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: File \"/nas3/gpratt/clipper/clipper/data/regions/utr3.hg19.bed\" does not exist"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#gets gene targets (for all imp datasets, ann asked me for this a while back)\n",
      "\n",
      "gencode = open(\"/nas3/yeolab/Genome/ensembl/gtf/gencode.v17.annotation.gtf\")\n",
      "\n",
      "gencode = pybedtools.BedTool(\"/nas3/yeolab/Genome/ensembl/gtf/gencode.v17.annotation.gtf\")\n",
      "converstion_dict = {}\n",
      "for interval in gencode:\n",
      "    try:\n",
      "        converstion_dict[interval.attrs['gene_id'].split(\".\")[0]] = interval.attrs['gene_name']\n",
      "    except:\n",
      "        pass"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result_dict = {}\n",
      "track_items = \"\"\n",
      "for sample in clip_df[clip_df['Antibody'].str.contains(\"FXR2|PTB|PAPD5|DGCR8\")].index:\n",
      "    cur_sample = pybedtools.BedTool(sample + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\")\n",
      "    cur_result = cur_sample.intersect(utr3_regions, u=True, s=True)\n",
      "    result_dict[sample] = Counter()\n",
      "    for interval in cur_result:\n",
      "        result_dict[sample][interval.name.split(\"_\")[0]] += 1\n",
      "    file_name = sample + \"_\" + \"_\".join(clip_df.ix[sample][['Cell Type', 'Antibody']]) + \".txt\"\n",
      "    print file_name\n",
      "    with open(file_name, 'w') as outfile:\n",
      "        for gene, count in result_dict[sample].most_common():\n",
      "            outfile.write(converstion_dict[gene.split(\".\")[0]] + \"\\t\" + str(count) +  \"\\n\")\n",
      "    track_items += (sample + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.fixed.bb \" + \n",
      "                    sample + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.pos.bw \" +\n",
      "                    sample + \".polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.neg.bw \")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clip_df.groupby[['Antibody', 'Species']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pwd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = Counter()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x[1] = 5\n",
      "x[2] = 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x.most_common()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "{name: len(value) for name, value in result_dict.items()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /nas3/gpratt/projects/public_clip/v2_re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls *.bed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd beds\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beds = !ls *.bed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beds = {bed.split(\".\")[0] : pybedtools.BedTool(bed) for bed in beds}\n",
      "beds_names = {name : [interval.name.split(\"_\")[0] for interval in bedtool] for name, bedtool in beds.items()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "human_db = \"/nas3/yeolab/Genome/ensembl/gtf/gencode.v17.annotation.gtf.db\"\n",
      "db = gffutils.FeatureDB(human_db)\n",
      "genes = db.features_of_type('gene') \n",
      "type_dict = {}\n",
      "ont_dict = {}\n",
      "for gene in list(genes):\n",
      "    gene_id = gene.attributes['gene_id']\n",
      "    #gene_dict[gene_id] = {\"gene_type\" : \"\", \"ont\" : \"\"}\n",
      "    if 'gene_type' in dict(gene.attributes):\n",
      "        type_dict[gene_id] = gene.attributes['gene_type']\n",
      "    if 'ont' in dict(gene.attributes):\n",
      "        print gene.attributes['ont']\n",
      "        ont_dict[gene_id] = gene.attributes['ont'] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_counts = pd.Series(Counter(type_dict.values()), name=\"Total\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "types = {}\n",
      "result = []\n",
      "for bed_name, gene_names in beds_names.items():\n",
      "    types[bed_name] = []\n",
      "    for gene_name in gene_names:\n",
      "        try:\n",
      "            types[bed_name].append(type_dict[gene_name])\n",
      "        except:\n",
      "            types[bed_name].append(\"error\")\n",
      "            \n",
      "    result.append(pd.Series(Counter(types[bed_name]), name=bed_name))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts_df = pd.DataFrame(result + [total_counts]).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = {}\n",
      "for sample in types.keys():\n",
      "    sample_dict = {}\n",
      "    for name, count in Counter(types[sample]).items():\n",
      "        drawn = count\n",
      "        total = len(type_dict.values())\n",
      "        total_possible = Counter(type_dict.values())[name]\n",
      "        total_drawn = sum(Counter(types[sample]).values())\n",
      "        pVal = (hypergeom.sf(drawn, total, total_possible, total_drawn)) * len(Counter(types[sample]))\n",
      "\n",
      "        sample_dict[name] = min(pVal, 1)\n",
      "        results[sample + \"_pval\"] = pd.Series(sample_dict, name= sample + \"_p-value\")\n",
      "counts_df = p_vals.merge(counts_df, left_index=True, right_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(counts_df.to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(clip_df.ix[\"SRR189775 \tSRR189776 \tSRR189777 \tSRR189778 \tSRR189779 \tSRR567525 \tSRR567526 SRR189781 \tSRR189780\".split()].to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = [srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.peaks.fixed.bb\" for srr in clip_df[clip_df.Species ==\"mm9\"].index]\n",
      "result += [srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.neg.bw\" for srr in clip_df[clip_df.Species ==\"mm9\"].index]\n",
      "result +=[srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.pos.bw\" for srr in clip_df[clip_df.Species ==\"mm9\"].index]\n",
      "print \" \".join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = [srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.peaks.fixed.bb\" for srr in clip_df[clip_df.Species ==\"hg19\"].index]\n",
      "result += [srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.neg.bw\" for srr in clip_df[clip_df.Species ==\"hg19\"].index]\n",
      "result +=[srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.pos.bw\" for srr in clip_df[clip_df.Species ==\"hg19\"].index]\n",
      "print \" \".join(result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\" \".join([srr + \".polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.peaks.bed\" for srr in clip_df[clip_df.Species ==\"mm9\"].index])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(clip_df.ix[\"SRR527730 SRR189780\".split()].to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "SRR527730.polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.peaks.bed\n",
      "chr12\t53858577\t53858605\tENSG00000197111.11_9_10\t0.000568462640558\t+\t53858588\t53858592\n",
      "\n",
      "SRR189780.polyATrim.adapterTrim.rmRep.rg.sorted.rmDup.sorted.peaks.bed\n",
      "chr5\t180259281\t180259309\tENSG00000245060.2_1_17\t7.30503372316e-12\t+\t180259292\t180259296\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}