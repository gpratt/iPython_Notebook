{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "from collections import defaultdict\n",
      "import itertools\n",
      "import gzip\n",
      "import os\n",
      "\n",
      "import gffutils\n",
      "from IPython.core.display import HTML, SVG\n",
      "import pandas as pd\n",
      "import pybedtools\n",
      "from scipy.stats import hypergeom\n",
      "import scipy.cluster\n",
      "\n",
      "from gscripts.general.dataviz import heatmap\n",
      "from gscripts.GO import hg19GO\n",
      "img_dir = \"/nas3/gpratt/Dropbox/UPF1/Upf1 paper/computational_figures/\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd /nas/nas0/gpratt/projects/upf1/analysis/notebook"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/nas/nas0/gpratt/projects/upf1/analysis/notebook\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "go = hg19GO()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cutoff = 2.04928504568\n",
      "WT_rip= pd.read_csv(\"wt_upf1_rip.csv\", index_col=0)\n",
      "rip_nontarget_df = WT_rip[ (-.5 < WT_rip.log2Ratio) & (WT_rip.log2Ratio < .5)]\n",
      "rip_target_df = WT_rip[WT_rip.log2Ratio > cutoff]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summary_frame = pd.DataFrame(index=(target_go.index | non_target_go.index))\n",
      "summary_frame[\"target\"] = target_go[\"Bonferroni-corrected Hypergeometric p-Value\"]\n",
      "summary_frame[\"non_target\"] = non_target_go[\"Bonferroni-corrected Hypergeometric p-Value\"]\n",
      "summary_frame = summary_frame.fillna(1)\n",
      "summary_frame = summary_frame[np.any(summary_frame <= 0.01, axis=1)]\n",
      "summary_frame = -np.log10(summary_frame + 0.000001)\n",
      "rowNames = [\"|\".join(go.GO[i]['name']) for i in summary_frame.index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'target_go' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-6-c66194d763d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msummary_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_go\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mnon_target_go\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msummary_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_go\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Bonferroni-corrected Hypergeometric p-Value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msummary_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"non_target\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_target_go\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Bonferroni-corrected Hypergeometric p-Value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msummary_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummary_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msummary_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msummary_frame\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_frame\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'target_go' is not defined"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "summary_frame"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "import matplotlib.gridspec as gridspec\n",
      "import matplotlib.font_manager as fm\n",
      "\n",
      "path = '/home/lovci/fonts/HelveticaLight.ttf'\n",
      "helvetica = fm.FontProperties(fname=path)\n",
      "\n",
      "def clusterGram(data, colLabels, rowLabels, distance_metric = 'euclidean', linkage_method = 'average', \n",
      "             clusterRows=True, clusterCols=True, timeSeries=False, doCovar=False, realdata=None):\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    Run hierarchical clustering on data. Creates a heatmap of cluster-ordered data\n",
      "    heavy-lifting is done by:\n",
      "    \n",
      "    gets distances between rows/columns\n",
      "    \n",
      "    y_events = scipy.spatial.distance.pdist(data, distance_metric)\n",
      "\n",
      "    calculates the closest rows/columns\n",
      "\n",
      "    Z_events = scipy.cluster.hierarchy.linkage(y_events, linkage_method)\n",
      "\n",
      "    genereates dendrogram (tree)\n",
      "\n",
      "    d_events = scipy.cluster.hierarchy.dendrogram(Z_events, no_labels=True) \n",
      "    \n",
      "    set outfile == \"None\" to inibit saving an eps file (only show it, don't save it)\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    if clusterRows:\n",
      "        print \"getting row distance matrix\"\n",
      "        y_events = scipy.spatial.distance.pdist(data, distance_metric)\n",
      "        print \"calculating linkages\"\n",
      "        Z_events = scipy.cluster.hierarchy.linkage(y_events, linkage_method, metric=distance_metric)\n",
      "\n",
      "    if clusterCols:\n",
      "        print \"getting column distance matrix\"    \n",
      "        y_samples = scipy.spatial.distance.pdist(np.transpose(data), distance_metric)\n",
      "        print \"calculating linkages\"    \n",
      "        Z_samples = scipy.cluster.hierarchy.linkage(y_samples, linkage_method, metric=distance_metric)\n",
      "    else:\n",
      "        if doCovar:\n",
      "            raise ValueError\n",
      "\n",
      "    fig = plt.figure(figsize=(12,30))\n",
      "\n",
      "    gs = gridspec.GridSpec(12,16)\n",
      "\n",
      "    ax1 = fig.add_subplot(gs[1:11, 1:3])\n",
      "\n",
      "    ax1.set_xticks([])\n",
      "    ax1.set_yticks([])\n",
      "    ax1.set_axis_off()\n",
      "    nRow, nCol = data.shape\n",
      "    print \"nRow: %d\" %nRow\n",
      "    if realdata != None:\n",
      "        print realdata.shape\n",
      "        print data.shape\n",
      "\n",
      "        assert realdata.shape == data.shape\n",
      "\n",
      "        reordered = realdata\n",
      "    else:\n",
      "        reordered = data\n",
      "        \n",
      "    event_order = range(nRow)\n",
      "    if clusterRows:\n",
      "        d_events = scipy.cluster.hierarchy.dendrogram(Z_events, orientation='right', no_labels=True)\n",
      "        event_order = d_events['leaves']\n",
      "        reordered = reordered[event_order,:]\n",
      "        \n",
      "    ax2 = fig.add_subplot(gs[0:1, 3:9])\n",
      "\n",
      "    ax2.set_xticks([])\n",
      "    ax2.set_yticks([])\n",
      "    ax2.set_axis_off()\n",
      "    sample_order = range(nCol)\n",
      "    if clusterCols:\n",
      "        d_samples = scipy.cluster.hierarchy.dendrogram(Z_samples, no_labels=True)    \n",
      "        sample_order = d_samples['leaves']\n",
      "        reordered = reordered[:,sample_order]\n",
      "    axmatrix = fig.add_subplot(gs[1:11, 3:9])\n",
      "    bds = np.max(abs(reordered))\n",
      "    if timeSeries:\n",
      "        norm = mpl.colors.Normalize(vmin=-bds, vmax=bds)\n",
      "    else:\n",
      "        norm = None\n",
      "        \n",
      "\n",
      "    cmap = pylab.cm.bone_r\n",
      "        \n",
      "    im = axmatrix.matshow(reordered, aspect='auto', origin='lower', cmap=cmap, norm=norm)\n",
      "    axmatrix.set_xticks([])\n",
      "    axmatrix.yaxis.tick_right()\n",
      "    axmatrix.set_yticks(range(nRow))\n",
      "    axmatrix.set_yticklabels([rowLabels[i] for i in event_order], fontsize=8)\n",
      "    axcolor = fig.add_subplot(gs[1:11, 0])\n",
      "\n",
      "    #\n",
      "    cbTicks = [np.min(data), np.mean(data), np.max(data)]\n",
      "    cb = fig.colorbar(im, cax=axcolor, ticks=cbTicks, use_gridspec=True)\n",
      "    cb.ax.set_yticklabels(map(lambda x: \"%.2f\" %x, cbTicks))\n",
      "    axcolor.yaxis.tick_left()\n",
      "    #axRowLabel = pylab.subplot(gs[1:6, 9:13])\n",
      "    #print nRow\n",
      "\n",
      "\n",
      "    #axRowLabel.set_yticks(map(lambda x: x+.5, range(nRow)))\n",
      "        \n",
      "    \n",
      "    \n",
      "    axlabel = fig.add_subplot(gs[11:, 3:9]) \n",
      "\n",
      "    step = 1./nCol\n",
      "    for i, ind in enumerate(sample_order):\n",
      "        xpos = (i*step)+(step/2)\n",
      "        fig.text(xpos,1, colLabels[ind] , rotation=90,verticalalignment='top', horizontalalignment='center')\n",
      "    axlabel.set_xticks([])\n",
      "    axlabel.set_yticks([])\n",
      "    axlabel.set_axis_off()\n",
      "    \n",
      "    #fig.show()\n",
      "    #pylab.tight_layout()\n",
      "\n",
      "    if doCovar:\n",
      "        cluster_covariance(data, colLabels, distance_metric = distance_metric, linkage_method = linkage_method)\n",
      "        \n",
      "    return fig, event_order, sample_order"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig, event_order, sample_order = clusterGram(np.array(summary_frame), summary_frame.columns, rowNames)\n",
      "fig.savefig(os.path.join(img_dir, \"ontology_cluster.svg\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig.savefig(\"foo.png\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%pylab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GO_enrichment(geneList, ontology, expressedGenes = None, printIt=False, pCut = 1000000, xRef = {}):\n",
      "    lenAllGenes, lenTheseGenes =  len(expressedGenes), len(geneList)\n",
      "    \n",
      "    pValues = defaultdict()\n",
      "    nCmps = 0\n",
      "\n",
      "    for GOTerm, GOGenes in ontology.items():\n",
      "        inBoth = GOGenes['genes'].intersection(geneList)\n",
      "        expressedGOGenes = GOGenes['genes'].intersection(expressedGenes)\n",
      "        if len(inBoth) <= 3 or len(expressedGOGenes) < 5:\n",
      "            pValues[GOTerm] = 'notest'\n",
      "            continue\n",
      "            \n",
      "        pVal = (1.-hypergeom.cdf(len(inBoth), lenAllGenes, len(expressedGOGenes), lenTheseGenes))\n",
      "        if pVal < 0:\n",
      "            pVal = 0 \n",
      "        symbols = []\n",
      "        for ensg in inBoth:\n",
      "            if ensg in xRef:\n",
      "                symbols.append(xRef[ensg])\n",
      "            else:\n",
      "                symbols.append(ensg)\n",
      "        pValues[GOTerm] = (pVal, len(inBoth), len(expressedGOGenes), len(GOGenes['genes']), inBoth, symbols)\n",
      "        \n",
      "    for k, v in pValues.items():\n",
      "        try:\n",
      "            pValues[k][0] = v * float(nCmps) #bonferroni correction\n",
      "        except:\n",
      "            pass\n",
      "    import operator\n",
      "    y  = []\n",
      "\n",
      "    sorted_x = sorted(pValues.iteritems(), key=operator.itemgetter(1))\n",
      "\n",
      "    for k, v in sorted_x:\n",
      "        if v == \"notest\":\n",
      "            continue\n",
      "        if not type(k) == str:\n",
      "            continue\n",
      "        try:\n",
      "            if v[0] > pCut:\n",
      "                continue\n",
      "            if printIt:\n",
      "                [k, \"|\".join(ontology[k]['name']), v[0], v[1], v[2], v[3], \",\".join(v[4]),  \",\".join(v[5])]\n",
      "                #print k, \"|\".join(ontology[k]['name']), \"%.3e\" %v[0], v[1], v[2], v[3], \"|\".join(v[3])\n",
      "            y.append([k, \"|\".join(ontology[k]['name']), v[0], v[1], v[2], v[3], \",\".join(v[4]), \",\".join(v[5])])\n",
      "            \n",
      "        except:\n",
      "            pass\n",
      "\n",
      "    try:\n",
      "        df = pd.DataFrame(y, columns=['GO Term ID', 'GO Term Description', 'Bonferroni-corrected Hypergeometric p-Value', 'N Genes in List and GO Category', 'N Expressed Genes in GO Category', 'N Genes in GO category', 'Ensembl Gene IDs in List', 'Gene symbols in List'])\n",
      "        df.set_index('GO Term ID', inplace=True)\n",
      "    except:\n",
      "        df = pd.DataFrame(None, columns=['GO Term ID', 'GO Term Description', 'Bonferroni-corrected Hypergeometric p-Value', 'N Genes in List and GO Category', 'N Expressed Genes in GO Category', 'N Genes in GO category', 'Ensembl Gene IDs in List', 'Gene symbols in List'])\n",
      "\n",
      "    return df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = \"/nas3/gpratt/projects/upf1/analysis/analysis_v2/clip/\"\n",
      "\n",
      "\n",
      "beds = { 'DEAA' : pybedtools.BedTool(path + \"UPF1_1_2.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed\"),\n",
      "         'K498A': pybedtools.BedTool(path + 'UPF1_3_4.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed'),\n",
      "         'WT'   : pybedtools.BedTool(path + 'FJM_W1_NoIndex_L001_R1.polyATrim.adapterTrim.rmRep.sorted.rg.rmDup.peaks.bed')\n",
      "         }"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beds_names = {name : [interval.name.split(\"_\")[0] for interval in bedtool] for name, bedtool in beds.items()}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "human_db = \"/nas3/yeolab/Genome/ensembl/gtf/gencode.v17.annotation.gtf.db\"\n",
      "db = gffutils.FeatureDB(human_db)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "genes = db.features_of_type('gene') \n",
      "type_dict = {}\n",
      "ont_dict = {}\n",
      "for gene in list(genes):\n",
      "    gene_id = gene.attributes['gene_id']\n",
      "    #gene_dict[gene_id] = {\"gene_type\" : \"\", \"ont\" : \"\"}\n",
      "    if 'gene_type' in dict(gene.attributes):\n",
      "        type_dict[gene_id] = gene.attributes['gene_type']\n",
      "    if 'ont' in dict(gene.attributes):\n",
      "        print gene.attributes['ont']\n",
      "        ont_dict[gene_id] = gene.attributes['ont'] \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "types = {}\n",
      "for bed_name, gene_names in beds_names.items():\n",
      "    types[bed_name] = []\n",
      "    for gene_name in gene_names:\n",
      "        try:\n",
      "            types[bed_name].append(type_dict[gene_name])\n",
      "        except:\n",
      "            types[bed_name].append(\"error\")\n",
      "            \n",
      "wt_counts = pd.Series(Counter(types['WT']), name=\"WT\")\n",
      "deaa_counts = pd.Series(Counter(types['DEAA']), name=\"DEAA\")\n",
      "k498a_counts = pd.Series(Counter(types['K498A']), name=\"K498A\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "total_counts = pd.Series(Counter(type_dict.values()), name=\"Total\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "counts_df = pd.DataFrame([wt_counts, deaa_counts, k498a_counts, total_counts]).T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "results = {}\n",
      "for sample in ['WT', 'DEAA', 'K498A']:\n",
      "    sample_dict = {}\n",
      "    for name, count in Counter(types[sample]).items():\n",
      "        drawn = count\n",
      "        total = len(type_dict.values())\n",
      "        total_possible = Counter(type_dict.values())[name]\n",
      "        total_drawn = sum(Counter(types[sample]).values())\n",
      "        pVal = (hypergeom.sf(drawn, total, total_possible, total_drawn)) * len(Counter(types[sample]))\n",
      "\n",
      "        sample_dict[name] = min(pVal, 1)\n",
      "        results[sample + \"_pval\"] = pd.Series(sample_dict, name= sample + \"_p-value\")\n",
      "counts_df = p_vals.merge(counts_df, left_index=True, right_index=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML(counts_df.to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gene groups over-represented between different samples "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mm9GO_to_ENSG = pd.read_table(gzip.open(\"/nas3/lovci/projects/GO/mm9.ENSG_to_GO.txt.gz\"))\n",
      "hg19GO_to_ENSG = pd.read_table(gzip.open(\"/nas3/lovci/projects/GO/hg19.ENSG_to_GO.txt.gz\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generateOntology(df):\n",
      "    ontology = defaultdict(lambda:  {'genes': set(), 'name': set(), 'domain': set()})\n",
      "    allGenesInOntologies = set(df.get('Ensembl Gene ID'))\n",
      "    for GO, gene, domain, name in itertools.izip(df.get('GO Term Accession'), df.get('Ensembl Gene ID'), df.get('GO domain'), df.get('GO Term Name')):\n",
      "        ontology[GO]['genes'].add(gene)\n",
      "        \n",
      "        ontology[GO]['name'].add(name)\n",
      "        ontology[GO]['domain'].add(domain)\n",
      "        ontology[GO]['nGenes'] = len(ontology[GO]['genes'])\n",
      "    return ontology, allGenesInOntologies"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "humanGeneXref = defaultdict()\n",
      "for k in np.array(hg19GO_to_ENSG.get(['Ensembl Gene ID', 'Associated Gene Name'])):\n",
      "    ensg = k[0]\n",
      "    gene = k[1]\n",
      "    humanGeneXref[ensg] = gene"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mm9GO, mm9allGenes = generateOntology(mm9GO_to_ENSG)\n",
      "hg19GO, hg19allGenes = generateOntology(hg19GO_to_ENSG)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ensembl_names = beds_names = {sample_name : [name.split(\".\")[0] for name in names] for sample_name, names in beds_names.items()}\n",
      "neuroGO = GO_enrichment(set(set(beds_names['WT'])), hg19GO, hg19allGenes, printIt=True, xRef=humanGeneXref) \n",
      "HTML(neuroGO.to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neuroGO = GO_enrichment(set(set(beds_names['DEAA'])), hg19GO, hg19allGenes, printIt=True, xRef=humanGeneXref) \n",
      "HTML(neuroGO.to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "neuroGO = GO_enrichment(set(set(beds_names['K498A'])), hg19GO, hg19allGenes, printIt=True, xRef=humanGeneXref) \n",
      "HTML(neuroGO.to_html())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    }
   ],
   "metadata": {}
  }
 ]
}